# 2023.2.24 第一次实验
## 对模型的修改：
    将视频序列的长度由15增加到了20，将模型隐神经元的数目增加到720， 初始学习率增加到0.01，epoch数增加到100
## 结果：
    最终的loss由570降低至460，但是输出的关节姿态仍然是混乱的
## 分析：
    模型拟合能力不够，并且将头部的方向向量和关节位置向量拼接在一起共同学习可能不是一个好主意

# 2023.2.26 第二次实验
## 对模型的修改
    将lr_steps由[20, 40]修改为[50, 100],epoch数目增加到150,将模型的head数目增加到10个,transformer子网络数目由6个增加到8个
## 结果：
    loss降低为411
## 分析：
    模型的拟合能力还是不够 需要将头部向量和姿态向量分开进行学习

# 2023.2.26 第三次实验
## 对模型的修改:
    将序列长度由20增加到了30，其余保持不变；修改了模型推理测试的代码
## 结果：
    loss提高到650
## 分析：
    模型没有拟合，学习能力不够

# 2023.2.26 第四次实验
## 对模型的修改:
    将模型的深度由N=8增加到N=16，梯度裁剪限制由30上升到50
## 结果：
    loss 697
## 分析：
    模型深度增加，但是loss上升？

# 2023.2.27 第五次实验
## 对模型的修改:
    将头部向量和姿态向量分开进行学习
    将模型的序列长度由30下降为20，增加随机数种子；
    更换优化器：将SGD替换为Adam + scheduler
    调整学习率，将初始lr 调整为0.1
## 结果：
    loss下降到20多，主要是因为去除了头部方向向量，loss的计算方式改变了
    测试出来的位姿还是很糟糕
## 分析：
    可能是因为在解码的时候没有一个正确的示范位姿引导，考虑在训练时加入示范位姿
    
# 2023.2.28 第六次实验
## 对模型的修改:
    将模型的dropout由0.5调整到0.1
    取消了positional encoding
## 结果：
    loss下降到10 但是输出的骨架信息还是毫无意义的混乱
## 分析：
    暂不清楚是dropout的问题还是取消位置编码的问题
    另外，这种直接输入特征来进行学习的transformer方法是否真的有效？
    模型学习到的似乎只是特征在未来的分布，而不是关节位置信息；
    下一步：不直接输入特征，而是输入图像来提取学习特征

# 2023.2.28 第七次实验
## 对模型的修改:
    改变模型的初始化方式：由xavier初始化更改为全0初始化
## 结果：
     loss下降到10 没什么用

    
    